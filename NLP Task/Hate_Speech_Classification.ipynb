{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySsIPBRiorxK"
   },
   "source": [
    "**Dataset**\n",
    "labeled dataset collected from twitter (Hate Speech.tsv)\n",
    "\n",
    "**Objective**\n",
    "classify tweets containing hate speech from other tweets. <br>\n",
    "0 -> no hate speech <br>\n",
    "1 -> contains hate speech <br>\n",
    "\n",
    "**Evaluation metric**\n",
    "macro f1 score\n",
    "\n",
    "**Steps**\n",
    "\n",
    "To classify hate speech in tweets, follow these key steps:\n",
    "\n",
    "1. **Data Preprocessing**: Clean text (remove punctuation, stopwords, etc.), lowercase, tokenize, and so on.\n",
    "2. **Text Representation**: Use Bag of Words, TF-IDF, or word embeddings (e.g., GloVe, Word2Vec, or FastText).\n",
    "3. **Modeling Approaches**:\n",
    "   - **Traditional Models**: Logistic Regression, Naive Bayes, SVM, Random Forest.\n",
    "   - **Deep Learning**: LSTM or RNN.\n",
    "4. **Evaluation**\n",
    "5. **Optimization**: Use hyperparameter tuning, regularization, and ensemble methods for better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-6lrKz6orxT"
   },
   "source": [
    "### Import used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyWWeDgRwLXB",
    "outputId": "65d7f75c-1232-4a0b-87d7-faed3d5caac4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eXUPo3g4orxV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Torch for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Imbalanced-learn\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# NLTK for text preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG8MkuvjorxX"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3a5_TBNwLXC"
   },
   "source": [
    "###### Note: search how to load the data from tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "BYeqhp66orxY",
    "outputId": "846eb157-8dcd-4497-e7db-3e020acdb3fd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 31535,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9238,\n        \"min\": 1,\n        \"max\": 31962,\n        \"num_unique_values\": 31535,\n        \"samples\": [\n          822,\n          16265,\n          8867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29130,\n        \"samples\": [\n          \"this obviously  #tcot gets on &amp; #inaspanof maybe #allof two seconds after boarding - thinks he \\\"knows\\\" what\\u00e2\\u0080\\u00a6 \",\n          \"the @user gave #words with #ibbleobble some #fabtastic feedback! we're really  ! \\u00e2\\u0080\\u00a6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-71c885e4-a5c5-495a-a08b-b93ad5d89d81\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ððððð¦ð¦ð¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71c885e4-a5c5-495a-a08b-b93ad5d89d81')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-71c885e4-a5c5-495a-a08b-b93ad5d89d81 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-71c885e4-a5c5-495a-a08b-b93ad5d89d81');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-711ae238-269d-47cf-b4e5-17945c3c610c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-711ae238-269d-47cf-b4e5-17945c3c610c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-711ae238-269d-47cf-b4e5-17945c3c610c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run  \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2                                                                                                         bihday your majesty  \n",
       "3                                        #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦  \n",
       "4                                                                                      factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Hate Speech.tsv\", sep= \"\\t\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otPZJKzmwLXD"
   },
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_4MXCG8wLXD"
   },
   "source": [
    "It is a good practice to split the data before EDA helps maintain the integrity of the machine learning process, prevents data leakage, simulates real-world scenarios more accurately, and ensures reliable model performance evaluation on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47UConpxwLXD",
    "outputId": "aacb35aa-ae2e-4329-b6e8-3439dd320c0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (18921, 2), Validation Set: (6307, 2), Test Set: (6307, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split data into train and test (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into train and validation (75% train, 25% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Training Set: {X_train.shape}, Validation Set: {X_val.shape}, Test Set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a_mmwMjXwLXD"
   },
   "outputs": [],
   "source": [
    "# Combine features and labels for each dataset\n",
    "train_combined = pd.concat([X_train, y_train], axis=1)\n",
    "test_combined = pd.concat([X_test, y_test], axis=1)\n",
    "val_combined = pd.concat([X_val, y_val], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqWVKi_GorxZ"
   },
   "source": [
    "### EDA on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1zxJpFxorxa"
   },
   "source": [
    "- check NaNs\n",
    "  \n",
    "result:there is no need for dropping null in prepossing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVEttSujorxa",
    "outputId": "22e63a7a-c158-4aea-a214-b0fe67641118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the count of NaNs in training dataset features id       0\n",
      "tweet    0\n",
      "label    0\n",
      "dtype: int64 \n",
      "the count of NaNs in testing dataset featuresid       0\n",
      "tweet    0\n",
      "label    0\n",
      "dtype: int64 \n",
      "the count of NaNs in validation dataset featuresid       0\n",
      "tweet    0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in each column\n",
    "nan_counts_train = train_combined.isna().sum()\n",
    "nan_counts_test = test_combined.isna().sum()\n",
    "nan_counts_validation = val_combined.isna().sum()\n",
    "print(f\"the count of NaNs in training dataset features {nan_counts_train} \")\n",
    "print(f\"the count of NaNs in testing dataset features{nan_counts_test} \")\n",
    "print(f\"the count of NaNs in validation dataset features{nan_counts_validation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwjbzVaIorxb"
   },
   "source": [
    "- check duplicates\n",
    "\n",
    "there is no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_FlBWISorxb",
    "outputId": "7421282c-a584-48a3-93db-2ce084791d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of duplicated rows in training dataset : 0\n",
      "The count of duplicated rows in testing dataset : 0\n",
      "The count of duplicated rows in validation dataset : 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for duplicates in each combined dataset\n",
    "duplicates_train_combined = train_combined.duplicated().sum()\n",
    "duplicates_test_combined = test_combined.duplicated().sum()\n",
    "duplicates_val_combined = val_combined.duplicated().sum()\n",
    "\n",
    "# Print the count of duplicated rows in each dataset\n",
    "print(f\"The count of duplicated rows in training dataset : {duplicates_train_combined}\")\n",
    "print(f\"The count of duplicated rows in testing dataset : {duplicates_test_combined}\")\n",
    "print(f\"The count of duplicated rows in validation dataset : {duplicates_val_combined}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjIBFc35orxc"
   },
   "source": [
    "- show a representative sample of data texts to find out required preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zGFKzSCRorxc",
    "outputId": "a1c1a3a6-efc7-4e03-b63b-6b8205dce1cf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"sample_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10373,\n        \"min\": 3335,\n        \"max\": 30454,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3335,\n          7561,\n          30454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"take pop out for churrasco this sunday!   #fathersday\",\n          \"@user @user  #wishing you a lovely mid week wednesday   day\",\n          \"new video shows how  this guy  and how he staed to abuse and humiliated an muslim guy\\u00e2\\u0080\\u00a6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "sample_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b38edd85-d215-41a1-9e98-94578d25d017\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15827</th>\n",
       "      <td>16232</td>\n",
       "      <td>â #eur/usd unable to regain 1.1300 despite dovish fed   #blog #silver #gold #forex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>3335</td>\n",
       "      <td>take pop out for churrasco this sunday!   #fathersday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30026</th>\n",
       "      <td>30454</td>\n",
       "      <td>new video shows how  this guy  and how he staed to abuse and humiliated an muslim guyâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13620</th>\n",
       "      <td>13974</td>\n",
       "      <td>video: currently at @user @user    #cute #eyes #like #follow #instafit #</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7436</th>\n",
       "      <td>7561</td>\n",
       "      <td>@user @user  #wishing you a lovely mid week wednesday   day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b38edd85-d215-41a1-9e98-94578d25d017')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b38edd85-d215-41a1-9e98-94578d25d017 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b38edd85-d215-41a1-9e98-94578d25d017');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-d77ac1e0-f66d-4e96-8b96-06b69828ae71\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d77ac1e0-f66d-4e96-8b96-06b69828ae71')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-d77ac1e0-f66d-4e96-8b96-06b69828ae71 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          id  \\\n",
       "15827  16232   \n",
       "3220    3335   \n",
       "30026  30454   \n",
       "13620  13974   \n",
       "7436    7561   \n",
       "\n",
       "                                                                                          tweet  \n",
       "15827      â #eur/usd unable to regain 1.1300 despite dovish fed   #blog #silver #gold #forex  \n",
       "3220                                      take pop out for churrasco this sunday!   #fathersday  \n",
       "30026  new video shows how  this guy  and how he staed to abuse and humiliated an muslim guyâ¦  \n",
       "13620                  video: currently at @user @user    #cute #eyes #like #follow #instafit #  \n",
       "7436                                @user @user  #wishing you a lovely mid week wednesday   day  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = X_train.sample(5, random_state=42)\n",
    "\n",
    "# Print the representative sample\n",
    "sample_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqdSUtbdorxd"
   },
   "source": [
    "- check dataset balancing\n",
    "\n",
    "  The Dataset is not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBHrSvXhorxd",
    "outputId": "141cb856-140a-49a3-f551-0a82f503880d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training dataset:\n",
      "label\n",
      "0    0.928598\n",
      "1    0.071402\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution in testing dataset:\n",
      "label\n",
      "0    0.931505\n",
      "1    0.068495\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution in validation dataset:\n",
      "label\n",
      "0    0.931822\n",
      "1    0.068178\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution for training, testing, and validation datasets\n",
    "train_class_distribution = train_combined['label'].value_counts(normalize=True)\n",
    "test_class_distribution = test_combined['label'].value_counts(normalize=True)\n",
    "val_class_distribution = val_combined['label'].value_counts(normalize=True)\n",
    "\n",
    "# Print class distributions\n",
    "print(\"Class distribution in training dataset:\")\n",
    "print(train_class_distribution)\n",
    "\n",
    "print(\"\\nClass distribution in testing dataset:\")\n",
    "print(test_class_distribution)\n",
    "\n",
    "print(\"\\nClass distribution in validation dataset:\")\n",
    "print(val_class_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3wl_crkorxd"
   },
   "source": [
    "- Cleaning and Preprocessing are:\n",
    "    - 1-Fix Encoding Issues: As seen in the sample, there are encoding problems (â, â¦)\n",
    "    - 2-Remove Hashtags and Mentions\n",
    "    - 3-Remove Special Characters and Punctuation\n",
    "    - 4-Lowercasing: Convert all text to lowercase to standardize it.\n",
    "    - 5-Remove Stopwords\n",
    "    - 6-remove URLs if they are found\n",
    "    - 7-Lemmatization: Reduce words to their base forms (e.g., \"running\" → \"run\").\n",
    "    - 8- data is unbalanced we can use oversampling teq like ADASYN .\n",
    "    - 9-Tokenization: Break the text into individual words.\n",
    "    - 10-Handling Emojis: Emojis might carry sentiment and may need to be processed or kept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyJkqK9gorxe"
   },
   "source": [
    "### Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8VL483twLXF",
    "tags": []
   },
   "source": [
    "#### Use custom scikit-learn Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRtZEB5zwLXF"
   },
   "source": [
    "Using custom transformers in scikit-learn provides flexibility, reusability, and control over the data transformation process, allowing you to seamlessly integrate with scikit-learn's pipelines, enabling you to combine multiple preprocessing steps and modeling into a single workflow. This makes your code more modular, readable, and easier to maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6qXpReiwLXF",
    "tags": []
   },
   "source": [
    "##### link: https://www.andrewvillazon.com/custom-scikit-learn-transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMYzjjT_wLXF"
   },
   "source": [
    "#### Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YafdtaFUnO66"
   },
   "outputs": [],
   "source": [
    "class CustomTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_features=1000, vectorizer=None):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_preprocessed = X['tweet'].apply(self.preprocess_text)\n",
    "        if self.vectorizer:\n",
    "            self.vectorizer.fit(X_preprocessed)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_preprocessed = X['tweet'].apply(self.preprocess_text)\n",
    "        if self.vectorizer:\n",
    "            X_transformed = self.vectorizer.transform(X_preprocessed.astype(str)).toarray()\n",
    "            return X_transformed\n",
    "        return X_preprocessed\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        X_preprocessed = X['tweet'].apply(self.preprocess_text)\n",
    "        if self.vectorizer:\n",
    "            X_transformed = self.vectorizer.fit_transform(X_preprocessed.astype(str)).toarray()\n",
    "            return X_transformed\n",
    "        return X_preprocessed\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = self.fix_encoding(text)\n",
    "        text = self.remove_hashtags_mentions(text)\n",
    "        text = self.remove_special_characters(text)\n",
    "        text = self.lowercase_text(text)\n",
    "        text = self.remove_stopwords(text)\n",
    "        text = self.remove_urls(text)\n",
    "        text = self.lemmatize_text(text)\n",
    "        text = self.tokenize_text(text)\n",
    "        return text\n",
    "\n",
    "    def fix_encoding(self, text):\n",
    "        return text.encode('utf-8', 'ignore').decode('utf-8') if isinstance(text, str) else str(text)\n",
    "\n",
    "    def remove_hashtags_mentions(self, text):\n",
    "        return re.sub(r'[@#]\\w+', '', text)\n",
    "\n",
    "    def remove_special_characters(self, text):\n",
    "        return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    def lowercase_text(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        return ' '.join([word for word in text.split() if word not in self.stop_words])\n",
    "\n",
    "    def remove_urls(self, text):\n",
    "        return re.sub(r'http\\S+|www\\S+', '', text)\n",
    "\n",
    "    def lemmatize_text(self, text):\n",
    "        return ' '.join([self.lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "    def tokenize_text(self, text):\n",
    "        return ' '.join(word_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJepyP7Tn0Me",
    "outputId": "202fa9e9-d8b5-41c5-c9c7-0fa6992a9143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    17899\n",
      "0    17570\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the custom transformer without ADASYN\n",
    "transformer = CustomTextTransformer(max_features=1000,vectorizer=TfidfVectorizer(max_features=1000))\n",
    "\n",
    "\n",
    "# Transform training data\n",
    "X_train_transformed = transformer.fit_transform(X_train)\n",
    "\n",
    "# Apply ADASYN separately to transformed training data\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0JVxeTaoLpF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5b7ylQeUn0XG"
   },
   "outputs": [],
   "source": [
    "X_test_transformed = transformer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba0r1ASHorxf"
   },
   "source": [
    "**You  are doing Great so far!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9BhRQbYorxf"
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Au1FYDPzorxg"
   },
   "source": [
    "#### Extra: use scikit-learn pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojRx3QnBwLXG"
   },
   "source": [
    "##### link: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5soMaobJwLXG"
   },
   "source": [
    "Using pipelines in scikit-learn promotes better code organization, reproducibility, and efficiency in machine learning workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP5FZzmborxg"
   },
   "source": [
    "#### Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfh-G9HtvcFE"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size=1000, hidden_size=64, output_size=1, epochs=10, batch_size=32):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "\n",
    "        if len(lstm_out.shape) == 3:\n",
    "            lstm_out = lstm_out[:, -1, :]  \n",
    "        elif len(lstm_out.shape) == 2:\n",
    "            lstm_out = lstm_out[:, :self.hidden_size] \n",
    "\n",
    "        out = self.fc(lstm_out)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self(X_batch)\n",
    "                loss = self.criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = self(X_tensor)\n",
    "\n",
    "        predictions_binary = (predictions >= 0.5).float()\n",
    "\n",
    "        return predictions_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "D4RQMiYwwLXG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', CustomTextTransformer(max_features=1000, vectorizer=TfidfVectorizer(max_features=1000))),\n",
    "    ('adasyn', ADASYN(random_state=42)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "# Now you can fit the pipeline on training data and use it for predictions\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_logistic = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Mv4DCAawwLXG"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', CustomTextTransformer(max_features=1000, vectorizer=TfidfVectorizer(max_features=1000))),\n",
    "    ('adasyn', ADASYN(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mScHzImVvcQT",
    "outputId": "ecbdc2b4-dab5-4468-ceb7-d2b01d608316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.5308780670166016\n",
      "Epoch 2/10, Loss: 0.28685304522514343\n",
      "Epoch 3/10, Loss: 0.5718701481819153\n",
      "Epoch 4/10, Loss: 0.29492565989494324\n",
      "Epoch 5/10, Loss: 0.31292545795440674\n",
      "Epoch 6/10, Loss: 0.38197338581085205\n",
      "Epoch 7/10, Loss: 0.3122020959854126\n",
      "Epoch 8/10, Loss: 0.5348643660545349\n",
      "Epoch 9/10, Loss: 0.17346535623073578\n",
      "Epoch 10/10, Loss: 0.1454213410615921\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline with CustomTextTransformer, ADASYN, and LSTMClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', CustomTextTransformer(max_features=1000, vectorizer=TfidfVectorizer(max_features=1000))),\n",
    "    ('adasyn', ADASYN(random_state=42)),\n",
    "    ('classifier', LSTMClassifier(input_size=1000, hidden_size=64, epochs=10, batch_size=32))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the pipeline\n",
    "y_pred_lstm = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85JlkIQXorxg"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbLukeDkwLXG"
   },
   "source": [
    "**Evaluation metric:**\n",
    "macro f1 score\n",
    "\n",
    "Macro F1 score is a useful metric in scenarios where you want to evaluate the overall performance of a multi-class classification model, **particularly when the classes are imbalanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAMgtVqUwLXG"
   },
   "source": [
    "![Calculation](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/639c3d934e82c1195cdf3c60_macro-f1.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LogisticRegression with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IA4YjKf4wLXG",
    "outputId": "a71c227d-ad0c-4920-f68f-f02646008959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5879052172791551\n"
     ]
    }
   ],
   "source": [
    "f1_macro = f1_score(y_test, y_pred_logistic, average='macro')\n",
    "\n",
    "print(\"F1 Score:\", f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandomForestClassifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37C70N6Aorxh",
    "outputId": "06a44983-1893-4324-d87a-6bf50af50ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6183633905152892\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred_rf, average='macro')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LSTMClassifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxBF_HEsorxh",
    "outputId": "2c8721e8-c79b-4cb1-a987-c65eee8797fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6091836863525852\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_lstm, average='macro')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhVFUaIcorxh"
   },
   "source": [
    "### Enhancement\n",
    "\n",
    "- Using different text representation or modeling techniques\n",
    "- Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use glove instead of TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4h1Danvorxh",
    "outputId": "442fe87f-60d3-44e3-81b8-0537b7c34ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "embedding_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "class EmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, embedding_model, embedding_dim=100):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([self._average_embedding(doc) for doc in X])\n",
    "\n",
    "    def _average_embedding(self, doc):\n",
    "        words = doc.split()\n",
    "        word_embeddings = [self.embedding_model[word] for word in words if word in self.embedding_model]\n",
    "        return np.mean(word_embeddings, axis=0) if word_embeddings else np.zeros(self.embedding_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "m5eAl72AdluJ"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', CustomTextTransformer(max_features=1000, vectorizer=None)),\n",
    "    ('embedding', EmbeddingTransformer(embedding_model=embedding_model)),\n",
    "    ('adasyn', ADASYN(random_state=42)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit and predict with the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_logistic_glove = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZDsCjdqsorxi"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', CustomTextTransformer(max_features=1000, vectorizer=None)),\n",
    "    ('embedding', EmbeddingTransformer(embedding_model=embedding_model)),\n",
    "    ('adasyn', ADASYN(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit and predict with the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_rf_glove = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gh8lcOzkwLXH",
    "outputId": "fa2f624e-adba-4759-f53a-7fe29de81176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.42926865816116333\n",
      "Epoch 2/10, Loss: 0.29352521896362305\n",
      "Epoch 3/10, Loss: 0.36207205057144165\n",
      "Epoch 4/10, Loss: 0.09106875956058502\n",
      "Epoch 5/10, Loss: 0.19850663840770721\n",
      "Epoch 6/10, Loss: 0.27941569685935974\n",
      "Epoch 7/10, Loss: 0.1117481142282486\n",
      "Epoch 8/10, Loss: 0.29841166734695435\n",
      "Epoch 9/10, Loss: 0.06586093455553055\n",
      "Epoch 10/10, Loss: 0.11626700311899185\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', CustomTextTransformer(max_features=1000, vectorizer=None)),\n",
    "    ('embedding', EmbeddingTransformer(embedding_model=embedding_model)),\n",
    "    ('adasyn', ADASYN(random_state=42)),\n",
    "    ('classifier',LSTMClassifier(input_size=100, hidden_size=64, epochs=10, batch_size=32))\n",
    "])\n",
    "\n",
    "# Fit and predict with the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_lstm_glove = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LogisticRegression with glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pA9YbulwijKh",
    "outputId": "754090f9-1988-4b56-8c6c-8a66b297b974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5913852813185521\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred_logistic_glove, average='macro')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RandomForestClassifier with glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvTloLSsijUr",
    "outputId": "c3cc50c9-f755-41bd-c8d4-8aaa97440aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.719606430468441\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred_rf_glove, average='macro')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LSTMClassifier with glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgW_ELjcije2",
    "outputId": "aa9cf74c-0423-46af-eb01-d1e471a3f9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6643312874543827\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_lstm_glove, average='macro')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning for lstm with glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfWkvwaui58m",
    "outputId": "234a9762-c8b4-4b05-d8ad-c6602364ee60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: {'batch_size': 16, 'epochs': 5, 'hidden_size': 32}\n",
      "Epoch 1/5, Loss: 0.5170995593070984\n",
      "Epoch 2/5, Loss: 0.21430934965610504\n",
      "Epoch 3/5, Loss: 0.8821848630905151\n",
      "Epoch 4/5, Loss: 0.22437450289726257\n",
      "Epoch 5/5, Loss: 0.34859591722488403\n",
      "Validation f1_score: 0.6218548282197617\n",
      "Training with parameters: {'batch_size': 16, 'epochs': 5, 'hidden_size': 64}\n",
      "Epoch 1/5, Loss: 0.31929394602775574\n",
      "Epoch 2/5, Loss: 0.23752300441265106\n",
      "Epoch 3/5, Loss: 0.3831334412097931\n",
      "Epoch 4/5, Loss: 0.26279494166374207\n",
      "Epoch 5/5, Loss: 0.4612191617488861\n",
      "Validation f1_score: 0.6451704296619705\n",
      "Training with parameters: {'batch_size': 16, 'epochs': 5, 'hidden_size': 128}\n",
      "Epoch 1/5, Loss: 0.42075666785240173\n",
      "Epoch 2/5, Loss: 0.3708648979663849\n",
      "Epoch 3/5, Loss: 0.2890675365924835\n",
      "Epoch 4/5, Loss: 0.297117680311203\n",
      "Epoch 5/5, Loss: 0.3386310636997223\n",
      "Validation f1_score: 0.6723673831279523\n",
      "Training with parameters: {'batch_size': 16, 'epochs': 10, 'hidden_size': 32}\n",
      "Epoch 1/10, Loss: 0.43431615829467773\n",
      "Epoch 2/10, Loss: 0.27119022607803345\n",
      "Epoch 3/10, Loss: 0.16858696937561035\n",
      "Epoch 4/10, Loss: 0.33292582631111145\n",
      "Epoch 5/10, Loss: 0.18966396152973175\n",
      "Epoch 6/10, Loss: 0.11158215999603271\n",
      "Epoch 7/10, Loss: 0.624394953250885\n",
      "Epoch 8/10, Loss: 0.08026313036680222\n",
      "Epoch 9/10, Loss: 0.12670817971229553\n",
      "Epoch 10/10, Loss: 0.2075251191854477\n",
      "Validation f1_score: 0.6423010814045733\n",
      "Training with parameters: {'batch_size': 16, 'epochs': 10, 'hidden_size': 64}\n",
      "Epoch 1/10, Loss: 0.4232897162437439\n",
      "Epoch 2/10, Loss: 0.25288334488868713\n",
      "Epoch 3/10, Loss: 0.5607621073722839\n",
      "Epoch 4/10, Loss: 0.04082026332616806\n",
      "Epoch 5/10, Loss: 0.4270443618297577\n",
      "Epoch 6/10, Loss: 0.4541153907775879\n",
      "Epoch 7/10, Loss: 0.19672012329101562\n",
      "Epoch 8/10, Loss: 0.15165357291698456\n",
      "Epoch 9/10, Loss: 0.1142054945230484\n",
      "Epoch 10/10, Loss: 0.23090288043022156\n",
      "Validation f1_score: 0.7168094351953942\n",
      "Training with parameters: {'batch_size': 16, 'epochs': 10, 'hidden_size': 128}\n",
      "Epoch 1/10, Loss: 0.5544728636741638\n",
      "Epoch 2/10, Loss: 0.2158164083957672\n",
      "Epoch 3/10, Loss: 0.39917510747909546\n",
      "Epoch 4/10, Loss: 0.2680751383304596\n",
      "Epoch 5/10, Loss: 0.29142317175865173\n",
      "Epoch 6/10, Loss: 0.048006560653448105\n",
      "Epoch 7/10, Loss: 0.20126207172870636\n",
      "Epoch 8/10, Loss: 0.0569688156247139\n",
      "Epoch 9/10, Loss: 0.08626437932252884\n",
      "Epoch 10/10, Loss: 0.04051309451460838\n",
      "Validation f1_score: 0.7124191098381536\n",
      "Training with parameters: {'batch_size': 16, 'epochs': 15, 'hidden_size': 32}\n",
      "Epoch 1/15, Loss: 0.29608601331710815\n",
      "Epoch 2/15, Loss: 0.7718451619148254\n",
      "Epoch 3/15, Loss: 0.6714040040969849\n",
      "Epoch 4/15, Loss: 0.31251102685928345\n",
      "Epoch 5/15, Loss: 0.304982990026474\n",
      "Epoch 6/15, Loss: 0.20872347056865692\n",
      "Epoch 7/15, Loss: 0.30634668469429016\n",
      "Epoch 8/15, Loss: 0.35321882367134094\n",
      "Epoch 9/15, Loss: 0.17891144752502441\n",
      "Epoch 10/15, Loss: 0.2531587481498718\n",
      "Epoch 11/15, Loss: 0.3661670386791229\n",
      "Epoch 12/15, Loss: 0.0934830978512764\n",
      "Epoch 13/15, Loss: 0.057740215212106705\n",
      "Epoch 14/15, Loss: 0.009144297800958157\n",
      "Epoch 15/15, Loss: 0.05243522301316261\n",
      "Validation f1_score: 0.7157777970361383\n",
      "Training with parameters: {'batch_size': 16, 'epochs': 15, 'hidden_size': 64}\n",
      "Epoch 1/15, Loss: 0.12637478113174438\n",
      "Epoch 2/15, Loss: 0.46981754899024963\n",
      "Epoch 3/15, Loss: 0.8056260347366333\n",
      "Epoch 4/15, Loss: 0.18887761235237122\n",
      "Epoch 5/15, Loss: 0.0643853098154068\n",
      "Epoch 6/15, Loss: 0.10293667763471603\n",
      "Epoch 7/15, Loss: 0.17210425436496735\n",
      "Epoch 8/15, Loss: 0.038862165063619614\n",
      "Epoch 9/15, Loss: 0.019962642341852188\n",
      "Epoch 10/15, Loss: 0.14828412234783173\n",
      "Epoch 11/15, Loss: 0.03232812508940697\n",
      "Epoch 12/15, Loss: 0.2093106359243393\n",
      "Epoch 13/15, Loss: 0.13351400196552277\n",
      "Epoch 14/15, Loss: 0.18065790832042694\n",
      "Epoch 15/15, Loss: 0.006573365069925785\n",
      "Validation f1_score: 0.7184852294997799\n",
      "Training with parameters: {'batch_size': 16, 'epochs': 15, 'hidden_size': 128}\n",
      "Epoch 1/15, Loss: 0.3187783658504486\n",
      "Epoch 2/15, Loss: 0.19407998025417328\n",
      "Epoch 3/15, Loss: 0.24271097779273987\n",
      "Epoch 4/15, Loss: 0.2758508026599884\n",
      "Epoch 5/15, Loss: 0.7496299147605896\n",
      "Epoch 6/15, Loss: 0.1601666957139969\n",
      "Epoch 7/15, Loss: 0.1466558873653412\n",
      "Epoch 8/15, Loss: 0.412442684173584\n",
      "Epoch 9/15, Loss: 0.0701305940747261\n",
      "Epoch 10/15, Loss: 0.03962591290473938\n",
      "Epoch 11/15, Loss: 0.0062041436322033405\n",
      "Epoch 12/15, Loss: 0.008799212984740734\n",
      "Epoch 13/15, Loss: 0.19572515785694122\n",
      "Epoch 14/15, Loss: 0.06327437609434128\n",
      "Epoch 15/15, Loss: 0.023551490157842636\n",
      "Validation f1_score: 0.7415910403580969\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 5, 'hidden_size': 32}\n",
      "Epoch 1/5, Loss: 0.4765203595161438\n",
      "Epoch 2/5, Loss: 0.479055255651474\n",
      "Epoch 3/5, Loss: 0.35442161560058594\n",
      "Epoch 4/5, Loss: 0.558855414390564\n",
      "Epoch 5/5, Loss: 0.15827807784080505\n",
      "Validation f1_score: 0.6120612581920868\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 5, 'hidden_size': 64}\n",
      "Epoch 1/5, Loss: 0.5313034653663635\n",
      "Epoch 2/5, Loss: 0.7218102812767029\n",
      "Epoch 3/5, Loss: 0.13050676882266998\n",
      "Epoch 4/5, Loss: 0.35992512106895447\n",
      "Epoch 5/5, Loss: 0.13460178673267365\n",
      "Validation f1_score: 0.6313484204473438\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 5, 'hidden_size': 128}\n",
      "Epoch 1/5, Loss: 0.4499550461769104\n",
      "Epoch 2/5, Loss: 0.7973045110702515\n",
      "Epoch 3/5, Loss: 0.282764732837677\n",
      "Epoch 4/5, Loss: 0.16604311764240265\n",
      "Epoch 5/5, Loss: 0.4096648097038269\n",
      "Validation f1_score: 0.6744442229243383\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 10, 'hidden_size': 32}\n",
      "Epoch 1/10, Loss: 0.5033528208732605\n",
      "Epoch 2/10, Loss: 0.6328811645507812\n",
      "Epoch 3/10, Loss: 0.4613545835018158\n",
      "Epoch 4/10, Loss: 0.3812573552131653\n",
      "Epoch 5/10, Loss: 0.08815106004476547\n",
      "Epoch 6/10, Loss: 0.3372553288936615\n",
      "Epoch 7/10, Loss: 0.17040188610553741\n",
      "Epoch 8/10, Loss: 0.1148877665400505\n",
      "Epoch 9/10, Loss: 0.06685739010572433\n",
      "Epoch 10/10, Loss: 0.10046925395727158\n",
      "Validation f1_score: 0.648880941727401\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 10, 'hidden_size': 64}\n",
      "Epoch 1/10, Loss: 0.4077407717704773\n",
      "Epoch 2/10, Loss: 0.18792963027954102\n",
      "Epoch 3/10, Loss: 0.23815622925758362\n",
      "Epoch 4/10, Loss: 0.12276984006166458\n",
      "Epoch 5/10, Loss: 0.11349532753229141\n",
      "Epoch 6/10, Loss: 0.22925305366516113\n",
      "Epoch 7/10, Loss: 0.1977812796831131\n",
      "Epoch 8/10, Loss: 0.27449965476989746\n",
      "Epoch 9/10, Loss: 0.11825524270534515\n",
      "Epoch 10/10, Loss: 0.2392410784959793\n",
      "Validation f1_score: 0.6572037474075663\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 10, 'hidden_size': 128}\n",
      "Epoch 1/10, Loss: 0.27100369334220886\n",
      "Epoch 2/10, Loss: 0.435759961605072\n",
      "Epoch 3/10, Loss: 0.37263745069503784\n",
      "Epoch 4/10, Loss: 0.30028438568115234\n",
      "Epoch 5/10, Loss: 0.45337221026420593\n",
      "Epoch 6/10, Loss: 0.5710770487785339\n",
      "Epoch 7/10, Loss: 0.12217271327972412\n",
      "Epoch 8/10, Loss: 0.2576165199279785\n",
      "Epoch 9/10, Loss: 0.052398063242435455\n",
      "Epoch 10/10, Loss: 0.18426905572414398\n",
      "Validation f1_score: 0.6758329739245131\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 15, 'hidden_size': 32}\n",
      "Epoch 1/15, Loss: 0.3657451570034027\n",
      "Epoch 2/15, Loss: 0.13275304436683655\n",
      "Epoch 3/15, Loss: 0.33865422010421753\n",
      "Epoch 4/15, Loss: 0.5003899335861206\n",
      "Epoch 5/15, Loss: 0.36878663301467896\n",
      "Epoch 6/15, Loss: 0.5883826017379761\n",
      "Epoch 7/15, Loss: 0.5998014211654663\n",
      "Epoch 8/15, Loss: 0.44539591670036316\n",
      "Epoch 9/15, Loss: 0.21394720673561096\n",
      "Epoch 10/15, Loss: 0.2238350212574005\n",
      "Epoch 11/15, Loss: 0.08807512372732162\n",
      "Epoch 12/15, Loss: 0.1938316971063614\n",
      "Epoch 13/15, Loss: 0.22760044038295746\n",
      "Epoch 14/15, Loss: 0.162058487534523\n",
      "Epoch 15/15, Loss: 0.12338107824325562\n",
      "Validation f1_score: 0.6554423440273298\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 15, 'hidden_size': 64}\n",
      "Epoch 1/15, Loss: 0.5095111131668091\n",
      "Epoch 2/15, Loss: 0.4524051249027252\n",
      "Epoch 3/15, Loss: 0.08783949911594391\n",
      "Epoch 4/15, Loss: 0.5862668752670288\n",
      "Epoch 5/15, Loss: 0.5879068374633789\n",
      "Epoch 6/15, Loss: 0.8848488926887512\n",
      "Epoch 7/15, Loss: 0.10718584060668945\n",
      "Epoch 8/15, Loss: 0.12131432443857193\n",
      "Epoch 9/15, Loss: 0.10801670700311661\n",
      "Epoch 10/15, Loss: 0.11880861222743988\n",
      "Epoch 11/15, Loss: 0.06724067777395248\n",
      "Epoch 12/15, Loss: 0.027068639174103737\n",
      "Epoch 13/15, Loss: 0.1263047456741333\n",
      "Epoch 14/15, Loss: 0.09375779330730438\n",
      "Epoch 15/15, Loss: 0.06829118728637695\n",
      "Validation f1_score: 0.670960093225649\n",
      "Training with parameters: {'batch_size': 32, 'epochs': 15, 'hidden_size': 128}\n",
      "Epoch 1/15, Loss: 0.20537973940372467\n",
      "Epoch 2/15, Loss: 0.1281944215297699\n",
      "Epoch 3/15, Loss: 0.28378304839134216\n",
      "Epoch 4/15, Loss: 0.38392800092697144\n",
      "Epoch 5/15, Loss: 0.5549379587173462\n",
      "Epoch 6/15, Loss: 0.3548647463321686\n",
      "Epoch 7/15, Loss: 0.21184499561786652\n",
      "Epoch 8/15, Loss: 0.07012759894132614\n",
      "Epoch 9/15, Loss: 0.038498979061841965\n",
      "Epoch 10/15, Loss: 0.2084566354751587\n",
      "Epoch 11/15, Loss: 0.12166202813386917\n",
      "Epoch 12/15, Loss: 0.090590700507164\n",
      "Epoch 13/15, Loss: 0.017603663727641106\n",
      "Epoch 14/15, Loss: 0.053477056324481964\n",
      "Epoch 15/15, Loss: 0.010615678504109383\n",
      "Validation f1_score: 0.7264960971379011\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 5, 'hidden_size': 32}\n",
      "Epoch 1/5, Loss: 0.5172395706176758\n",
      "Epoch 2/5, Loss: 0.35980719327926636\n",
      "Epoch 3/5, Loss: 0.5525177121162415\n",
      "Epoch 4/5, Loss: 0.525397002696991\n",
      "Epoch 5/5, Loss: 0.3367363512516022\n",
      "Validation f1_score: 0.6177929535998872\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 5, 'hidden_size': 64}\n",
      "Epoch 1/5, Loss: 0.5368650555610657\n",
      "Epoch 2/5, Loss: 0.33980390429496765\n",
      "Epoch 3/5, Loss: 0.2393188178539276\n",
      "Epoch 4/5, Loss: 0.38478246331214905\n",
      "Epoch 5/5, Loss: 0.42610687017440796\n",
      "Validation f1_score: 0.6246737678584457\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 5, 'hidden_size': 128}\n",
      "Epoch 1/5, Loss: 0.5882459282875061\n",
      "Epoch 2/5, Loss: 0.4267105162143707\n",
      "Epoch 3/5, Loss: 0.3180520832538605\n",
      "Epoch 4/5, Loss: 0.37568023800849915\n",
      "Epoch 5/5, Loss: 0.2870793044567108\n",
      "Validation f1_score: 0.6387140022336129\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 10, 'hidden_size': 32}\n",
      "Epoch 1/10, Loss: 0.5305488109588623\n",
      "Epoch 2/10, Loss: 0.428059458732605\n",
      "Epoch 3/10, Loss: 0.2466905564069748\n",
      "Epoch 4/10, Loss: 0.4234984517097473\n",
      "Epoch 5/10, Loss: 0.3107863962650299\n",
      "Epoch 6/10, Loss: 0.37359681725502014\n",
      "Epoch 7/10, Loss: 0.27922049164772034\n",
      "Epoch 8/10, Loss: 0.23788340389728546\n",
      "Epoch 9/10, Loss: 0.3259926736354828\n",
      "Epoch 10/10, Loss: 0.26572591066360474\n",
      "Validation f1_score: 0.6204060544689436\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 10, 'hidden_size': 64}\n",
      "Epoch 1/10, Loss: 0.3340338170528412\n",
      "Epoch 2/10, Loss: 0.3155694007873535\n",
      "Epoch 3/10, Loss: 0.44771820306777954\n",
      "Epoch 4/10, Loss: 0.3108016848564148\n",
      "Epoch 5/10, Loss: 0.45433035492897034\n",
      "Epoch 6/10, Loss: 0.207153782248497\n",
      "Epoch 7/10, Loss: 0.26627469062805176\n",
      "Epoch 8/10, Loss: 0.3810889422893524\n",
      "Epoch 9/10, Loss: 0.19931547343730927\n",
      "Epoch 10/10, Loss: 0.2888270318508148\n",
      "Validation f1_score: 0.6288659374874164\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 10, 'hidden_size': 128}\n",
      "Epoch 1/10, Loss: 0.448222815990448\n",
      "Epoch 2/10, Loss: 0.4971075654029846\n",
      "Epoch 3/10, Loss: 0.375180721282959\n",
      "Epoch 4/10, Loss: 0.37124204635620117\n",
      "Epoch 5/10, Loss: 0.28373923897743225\n",
      "Epoch 6/10, Loss: 0.2700483500957489\n",
      "Epoch 7/10, Loss: 0.15564845502376556\n",
      "Epoch 8/10, Loss: 0.25727763772010803\n",
      "Epoch 9/10, Loss: 0.22793544828891754\n",
      "Epoch 10/10, Loss: 0.24614977836608887\n",
      "Validation f1_score: 0.6469634190758733\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 15, 'hidden_size': 32}\n",
      "Epoch 1/15, Loss: 0.48010414838790894\n",
      "Epoch 2/15, Loss: 0.34417322278022766\n",
      "Epoch 3/15, Loss: 0.3747071623802185\n",
      "Epoch 4/15, Loss: 0.5284573435783386\n",
      "Epoch 5/15, Loss: 0.4661153554916382\n",
      "Epoch 6/15, Loss: 0.28851762413978577\n",
      "Epoch 7/15, Loss: 0.37871572375297546\n",
      "Epoch 8/15, Loss: 0.3151138126850128\n",
      "Epoch 9/15, Loss: 0.26813623309135437\n",
      "Epoch 10/15, Loss: 0.23898053169250488\n",
      "Epoch 11/15, Loss: 0.25395169854164124\n",
      "Epoch 12/15, Loss: 0.23830600082874298\n",
      "Epoch 13/15, Loss: 0.2683700621128082\n",
      "Epoch 14/15, Loss: 0.1999201774597168\n",
      "Epoch 15/15, Loss: 0.3264705538749695\n",
      "Validation f1_score: 0.6502758836228884\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 15, 'hidden_size': 64}\n",
      "Epoch 1/15, Loss: 0.48424071073532104\n",
      "Epoch 2/15, Loss: 0.33681029081344604\n",
      "Epoch 3/15, Loss: 0.4015793800354004\n",
      "Epoch 4/15, Loss: 0.3411431312561035\n",
      "Epoch 5/15, Loss: 0.41832590103149414\n",
      "Epoch 6/15, Loss: 0.3413642346858978\n",
      "Epoch 7/15, Loss: 0.2723487615585327\n",
      "Epoch 8/15, Loss: 0.33568456768989563\n",
      "Epoch 9/15, Loss: 0.19490014016628265\n",
      "Epoch 10/15, Loss: 0.14715780317783356\n",
      "Epoch 11/15, Loss: 0.35434457659721375\n",
      "Epoch 12/15, Loss: 0.23874038457870483\n",
      "Epoch 13/15, Loss: 0.3577400743961334\n",
      "Epoch 14/15, Loss: 0.24749401211738586\n",
      "Epoch 15/15, Loss: 0.18378430604934692\n",
      "Validation f1_score: 0.6496489333383266\n",
      "Training with parameters: {'batch_size': 64, 'epochs': 15, 'hidden_size': 128}\n",
      "Epoch 1/15, Loss: 0.522053062915802\n",
      "Epoch 2/15, Loss: 0.49987542629241943\n",
      "Epoch 3/15, Loss: 0.4261994957923889\n",
      "Epoch 4/15, Loss: 0.39230430126190186\n",
      "Epoch 5/15, Loss: 0.3436654508113861\n",
      "Epoch 6/15, Loss: 0.5174264311790466\n",
      "Epoch 7/15, Loss: 0.3443140387535095\n",
      "Epoch 8/15, Loss: 0.1808968037366867\n",
      "Epoch 9/15, Loss: 0.21049563586711884\n",
      "Epoch 10/15, Loss: 0.24213740229606628\n",
      "Epoch 11/15, Loss: 0.0910385474562645\n",
      "Epoch 12/15, Loss: 0.16331849992275238\n",
      "Epoch 13/15, Loss: 0.10445258766412735\n",
      "Epoch 14/15, Loss: 0.19146254658699036\n",
      "Epoch 15/15, Loss: 0.1953863650560379\n",
      "Validation f1_score: 0.6698792909538616\n",
      "Best parameters: {'batch_size': 16, 'epochs': 15, 'hidden_size': 128, 'f1_score': 0.7415910403580969}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'hidden_size': [32, 64, 128],\n",
    "    'epochs': [5, 10, 15],\n",
    "    'batch_size': [16, 32, 64]\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for params in grid:\n",
    "    print(f\"Training with parameters: {params}\")\n",
    "\n",
    "    # Define the pipeline with current parameters\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessing', CustomTextTransformer(max_features=1000, vectorizer=None)),\n",
    "        ('embedding', EmbeddingTransformer(embedding_model=embedding_model)),\n",
    "        ('adasyn', ADASYN(random_state=42)),\n",
    "        ('classifier', LSTMClassifier(input_size=100, hidden_size=params['hidden_size'], epochs=params['epochs'], batch_size=params['batch_size']))\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on validation data\n",
    "    y_pred_val = pipeline.predict(X_val)\n",
    "\n",
    "    # Evaluate performance using F1 score\n",
    "    score = f1_score(y_val, y_pred_val, average='macro')\n",
    "    results.append({**params, 'f1_score': score})\n",
    "    print(f\"Validation f1_score: {score}\")\n",
    "\n",
    "# Get the best model based on F1 score\n",
    "best_params = max(results, key=lambda x: x['f1_score'])\n",
    "print(f\"Best parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdMJC_XsqLal",
    "outputId": "d0a69663-99d4-4ce3-a2f2-497c0fe59551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.23303402960300446\n",
      "Epoch 2/15, Loss: 0.5155577063560486\n",
      "Epoch 3/15, Loss: 0.4906882643699646\n",
      "Epoch 4/15, Loss: 0.22091908752918243\n",
      "Epoch 5/15, Loss: 0.05827739089727402\n",
      "Epoch 6/15, Loss: 0.43039825558662415\n",
      "Epoch 7/15, Loss: 0.40079304575920105\n",
      "Epoch 8/15, Loss: 0.16123683750629425\n",
      "Epoch 9/15, Loss: 0.0581737756729126\n",
      "Epoch 10/15, Loss: 0.18877704441547394\n",
      "Epoch 11/15, Loss: 0.20361539721488953\n",
      "Epoch 12/15, Loss: 0.316938579082489\n",
      "Epoch 13/15, Loss: 0.013389569707214832\n",
      "Epoch 14/15, Loss: 0.02015012502670288\n",
      "Epoch 15/15, Loss: 0.01455944124609232\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline with current parameters\n",
    "pipeline = Pipeline([\n",
    "        ('preprocessing', CustomTextTransformer(max_features=1000, vectorizer=None)),\n",
    "        ('embedding', EmbeddingTransformer(embedding_model=embedding_model)),\n",
    "        ('adasyn', ADASYN(random_state=42)),\n",
    "        ('classifier', LSTMClassifier(input_size=100, hidden_size=128, epochs=15, batch_size=16))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_lstm_glove_tuned = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fabfv2Zdqob6",
    "outputId": "fb8d93d7-c313-407c-ac83-bf4e340d60b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7361710571477604\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, y_pred_lstm_glove_tuned, average='macro')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GolshsUtwLXH"
   },
   "source": [
    "### Conclusion and final results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gkWK4EJp7Ym"
   },
   "source": [
    "### Summary\n",
    "\n",
    "1. **Exploratory Data Analysis (EDA)**:\n",
    "   - The dataset was found to be clean with no missing values or duplicates.\n",
    "\n",
    "2. **Data Imbalance**:\n",
    "   - The dataset was imbalanced, and **ADASYN** was used as an oversampling technique to balance the class distribution in the training data.\n",
    "\n",
    "3. **Preprocessing Steps**:\n",
    "   - **Encoding Fixes**: Resolved encoding issues.\n",
    "   - **Text Cleaning**: Removed hashtags, mentions, special characters, stopwords, and URLs.\n",
    "   - **Lemmatization and Tokenization**: Reduced words to base forms and split text into words.\n",
    "   - **Emoji Handling**: Emojis were preserved, considering their potential sentiment value.\n",
    "\n",
    "4. **Modeling**:\n",
    "   - **Logistic Regression**: Achieved an **F1 score of 0.5879**.\n",
    "   - **Random Forest**: Achieved a slightly better **F1 score of 0.618363**.\n",
    "   - **LSTM Classifier**: Outperformed the other models with the highest **F1 score of 0.609**.\n",
    "\n",
    "5. **Conclusions**:\n",
    "   - The **Random Forest** was the most effective.\n",
    "   - The **ADASYN** oversampling technique helped to address data imbalance effectively.\n",
    "\n",
    "\n",
    "   ### Model Enhancement and Hyperparameter Tuning\n",
    "\n",
    "#### **1. Using Pre-trained Word Embeddings (GloVe)**:\n",
    "   - The **GloVe word embeddings** (100-dimensional) were used to improve text representation.\n",
    "   - The following models were evaluated using the GloVe embeddings:\n",
    "\n",
    "   **Pipeline for Logistic Regression:**\n",
    "   - **F1 Score**: 0.59138\n",
    "   \n",
    "   **Pipeline for Random Forest:**\n",
    "   - **F1 Score**: 0.71960\n",
    "   \n",
    "   **Pipeline for LSTM:**\n",
    "   - **F1 Score**: 0.66433\n",
    "   \n",
    "#### **2. Hyperparameter Tuning for LSTM Classifier**:\n",
    "   - **Hyperparameters tested**:\n",
    "     - `hidden_size`: [32, 64, 128]\n",
    "     - `epochs`: [5, 10, 15]\n",
    "     - `batch_size`: [16, 32, 64]\n",
    "   \n",
    "   - After tuning, the best hyperparameters were:\n",
    "     - `hidden_size`: 128\n",
    "     - `epochs`: 15\n",
    "     - `batch_size`: 16\n",
    "     - **Validation F1 Score**: 0.74159104\n",
    "     - **Test F1 Score**: 0.7361710571477604\n",
    "\n",
    "#### **3. Conclusions**:\n",
    "   - **GloVe embeddings** improved the performance of the models.\n",
    "   - **Random Forest** showed the best performance in terms of F1 score among the non-LSTM models.but after fine tuning for lstm , the lstm\n",
    "   one become better\n",
    "   - **LSTM Classifier** showed significant improvement after hyperparameter tuning and become the best model among the models\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nw1GVnYLorxi"
   },
   "source": [
    "#### Done!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
